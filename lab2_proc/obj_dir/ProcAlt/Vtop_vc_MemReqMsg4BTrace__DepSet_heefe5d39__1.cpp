// Verilated -*- C++ -*-
// DESCRIPTION: Verilator output: Design implementation internals
// See Vtop.h for the primary calling header

#include "verilated.h"
#include "verilated_dpi.h"

#include "Vtop__Syms.h"
#include "Vtop__Syms.h"
#include "Vtop_vc_MemReqMsg4BTrace.h"

VL_INLINE_OPT void Vtop_vc_MemReqMsg4BTrace___nba_comb__TOP__top__mem__memreq0_trace__1(Vtop_vc_MemReqMsg4BTrace* vlSelf) {
    if (false && vlSelf) {}  // Prevent unused
    Vtop__Syms* const __restrict vlSymsp VL_ATTR_UNUSED = vlSelf->vlSymsp;
    VL_DEBUG_IF(VL_DBG_MSGF("+            Vtop_vc_MemReqMsg4BTrace___nba_comb__TOP__top__mem__memreq0_trace__1\n"); );
    // Body
    if (((IData)(vlSelf->__PVT__val) ^ (IData)(vlSelf->__Vtogcov__val))) {
        vlSymsp->__Vcoverage[6359].fetch_add(1, std::memory_order_relaxed);
        vlSelf->__Vtogcov__val = vlSelf->__PVT__val;
    }
}

VL_INLINE_OPT void Vtop_vc_MemReqMsg4BTrace___nba_comb__TOP__top__mem__memreq0_trace__2(Vtop_vc_MemReqMsg4BTrace* vlSelf) {
    if (false && vlSelf) {}  // Prevent unused
    Vtop__Syms* const __restrict vlSymsp VL_ATTR_UNUSED = vlSelf->vlSymsp;
    VL_DEBUG_IF(VL_DBG_MSGF("+            Vtop_vc_MemReqMsg4BTrace___nba_comb__TOP__top__mem__memreq0_trace__2\n"); );
    // Body
    if (((IData)(vlSelf->__PVT__rdy) ^ (IData)(vlSelf->__Vtogcov__rdy))) {
        vlSymsp->__Vcoverage[6360].fetch_add(1, std::memory_order_relaxed);
        vlSelf->__Vtogcov__rdy = vlSelf->__PVT__rdy;
    }
}

VL_INLINE_OPT void Vtop_vc_MemReqMsg4BTrace___nba_sequent__TOP__top__mem__memreq1_trace__0(Vtop_vc_MemReqMsg4BTrace* vlSelf) {
    if (false && vlSelf) {}  // Prevent unused
    Vtop__Syms* const __restrict vlSymsp VL_ATTR_UNUSED = vlSelf->vlSymsp;
    VL_DEBUG_IF(VL_DBG_MSGF("+            Vtop_vc_MemReqMsg4BTrace___nba_sequent__TOP__top__mem__memreq1_trace__0\n"); );
    // Body
    if (((IData)(vlSelf->__PVT__reset) ^ (IData)(vlSelf->__Vtogcov__reset))) {
        vlSymsp->__Vcoverage[6358].fetch_add(1, std::memory_order_relaxed);
        vlSelf->__Vtogcov__reset = vlSelf->__PVT__reset;
    }
}

VL_INLINE_OPT void Vtop_vc_MemReqMsg4BTrace___nba_comb__TOP__top__mem__memreq1_trace__0(Vtop_vc_MemReqMsg4BTrace* vlSelf) {
    if (false && vlSelf) {}  // Prevent unused
    Vtop__Syms* const __restrict vlSymsp VL_ATTR_UNUSED = vlSelf->vlSymsp;
    VL_DEBUG_IF(VL_DBG_MSGF("+            Vtop_vc_MemReqMsg4BTrace___nba_comb__TOP__top__mem__memreq1_trace__0\n"); );
    // Body
    if (((IData)(vlSelf->__PVT__val) ^ (IData)(vlSelf->__Vtogcov__val))) {
        vlSymsp->__Vcoverage[6359].fetch_add(1, std::memory_order_relaxed);
        vlSelf->__Vtogcov__val = vlSelf->__PVT__val;
    }
}

VL_INLINE_OPT void Vtop_vc_MemReqMsg4BTrace___nba_comb__TOP__top__mem__memreq1_trace__1(Vtop_vc_MemReqMsg4BTrace* vlSelf) {
    if (false && vlSelf) {}  // Prevent unused
    Vtop__Syms* const __restrict vlSymsp VL_ATTR_UNUSED = vlSelf->vlSymsp;
    VL_DEBUG_IF(VL_DBG_MSGF("+            Vtop_vc_MemReqMsg4BTrace___nba_comb__TOP__top__mem__memreq1_trace__1\n"); );
    // Body
    vlSelf->__PVT__len = (3U & VL_SEL_IWII(77, vlSelf->__PVT__msg, 0x20U, 2U));
    vlSelf->__PVT__type_ = (7U & VL_SEL_IWII(77, vlSelf->__PVT__msg, 0x4aU, 3U));
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x4aU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x4aU)))) {
        vlSymsp->__Vcoverage[6361].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x4aU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x4aU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x4bU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x4bU)))) {
        vlSymsp->__Vcoverage[6362].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x4bU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x4bU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x4cU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x4cU)))) {
        vlSymsp->__Vcoverage[6363].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x4cU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x4cU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x42U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x42U)))) {
        vlSymsp->__Vcoverage[6364].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x42U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x42U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x43U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x43U)))) {
        vlSymsp->__Vcoverage[6365].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x43U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x43U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x44U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x44U)))) {
        vlSymsp->__Vcoverage[6366].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x44U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x44U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x45U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x45U)))) {
        vlSymsp->__Vcoverage[6367].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x45U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x45U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x46U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x46U)))) {
        vlSymsp->__Vcoverage[6368].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x46U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x46U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x47U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x47U)))) {
        vlSymsp->__Vcoverage[6369].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x47U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x47U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x48U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x48U)))) {
        vlSymsp->__Vcoverage[6370].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x48U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x48U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x49U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x49U)))) {
        vlSymsp->__Vcoverage[6371].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x49U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x49U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x22U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x22U)))) {
        vlSymsp->__Vcoverage[6372].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x22U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x22U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x23U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x23U)))) {
        vlSymsp->__Vcoverage[6373].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x23U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x23U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x24U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x24U)))) {
        vlSymsp->__Vcoverage[6374].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x24U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x24U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x25U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x25U)))) {
        vlSymsp->__Vcoverage[6375].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x25U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x25U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x26U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x26U)))) {
        vlSymsp->__Vcoverage[6376].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x26U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x26U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x27U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x27U)))) {
        vlSymsp->__Vcoverage[6377].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x27U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x27U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x28U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x28U)))) {
        vlSymsp->__Vcoverage[6378].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x28U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x28U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x29U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x29U)))) {
        vlSymsp->__Vcoverage[6379].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x29U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x29U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2aU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x2aU)))) {
        vlSymsp->__Vcoverage[6380].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x2aU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2aU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2bU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x2bU)))) {
        vlSymsp->__Vcoverage[6381].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x2bU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2bU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2cU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x2cU)))) {
        vlSymsp->__Vcoverage[6382].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x2cU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2cU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2dU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x2dU)))) {
        vlSymsp->__Vcoverage[6383].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x2dU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2dU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2eU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x2eU)))) {
        vlSymsp->__Vcoverage[6384].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x2eU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2eU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2fU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x2fU)))) {
        vlSymsp->__Vcoverage[6385].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x2fU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x2fU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x30U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x30U)))) {
        vlSymsp->__Vcoverage[6386].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x30U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x30U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x31U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x31U)))) {
        vlSymsp->__Vcoverage[6387].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x31U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x31U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x32U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x32U)))) {
        vlSymsp->__Vcoverage[6388].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x32U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x32U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x33U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x33U)))) {
        vlSymsp->__Vcoverage[6389].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x33U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x33U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x34U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x34U)))) {
        vlSymsp->__Vcoverage[6390].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x34U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x34U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x35U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x35U)))) {
        vlSymsp->__Vcoverage[6391].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x35U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x35U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x36U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x36U)))) {
        vlSymsp->__Vcoverage[6392].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x36U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x36U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x37U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x37U)))) {
        vlSymsp->__Vcoverage[6393].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x37U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x37U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x38U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x38U)))) {
        vlSymsp->__Vcoverage[6394].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x38U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x38U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x39U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x39U)))) {
        vlSymsp->__Vcoverage[6395].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x39U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x39U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3aU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x3aU)))) {
        vlSymsp->__Vcoverage[6396].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x3aU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3aU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3bU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x3bU)))) {
        vlSymsp->__Vcoverage[6397].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x3bU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3bU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3cU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x3cU)))) {
        vlSymsp->__Vcoverage[6398].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x3cU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3cU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3dU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x3dU)))) {
        vlSymsp->__Vcoverage[6399].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x3dU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3dU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3eU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x3eU)))) {
        vlSymsp->__Vcoverage[6400].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x3eU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3eU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3fU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x3fU)))) {
        vlSymsp->__Vcoverage[6401].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x3fU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x3fU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x40U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x40U)))) {
        vlSymsp->__Vcoverage[6402].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x40U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x40U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x41U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x41U)))) {
        vlSymsp->__Vcoverage[6403].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x41U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x41U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x20U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x20U)))) {
        vlSymsp->__Vcoverage[6404].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x20U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x20U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x21U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x21U)))) {
        vlSymsp->__Vcoverage[6405].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x21U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x21U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0U)))) {
        vlSymsp->__Vcoverage[6406].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 1U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 1U)))) {
        vlSymsp->__Vcoverage[6407].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(1U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 1U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 2U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 2U)))) {
        vlSymsp->__Vcoverage[6408].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(2U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 2U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 3U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 3U)))) {
        vlSymsp->__Vcoverage[6409].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(3U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 3U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 4U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 4U)))) {
        vlSymsp->__Vcoverage[6410].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(4U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 4U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 5U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 5U)))) {
        vlSymsp->__Vcoverage[6411].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(5U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 5U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 6U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 6U)))) {
        vlSymsp->__Vcoverage[6412].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(6U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 6U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 7U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 7U)))) {
        vlSymsp->__Vcoverage[6413].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(7U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 7U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 8U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 8U)))) {
        vlSymsp->__Vcoverage[6414].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(8U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 8U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 9U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 9U)))) {
        vlSymsp->__Vcoverage[6415].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(9U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 9U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xaU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0xaU)))) {
        vlSymsp->__Vcoverage[6416].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0xaU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xaU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xbU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0xbU)))) {
        vlSymsp->__Vcoverage[6417].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0xbU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xbU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xcU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0xcU)))) {
        vlSymsp->__Vcoverage[6418].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0xcU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xcU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xdU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0xdU)))) {
        vlSymsp->__Vcoverage[6419].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0xdU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xdU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xeU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0xeU)))) {
        vlSymsp->__Vcoverage[6420].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0xeU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xeU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xfU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0xfU)))) {
        vlSymsp->__Vcoverage[6421].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0xfU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0xfU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x10U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x10U)))) {
        vlSymsp->__Vcoverage[6422].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x10U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x10U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x11U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x11U)))) {
        vlSymsp->__Vcoverage[6423].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x11U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x11U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x12U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x12U)))) {
        vlSymsp->__Vcoverage[6424].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x12U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x12U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x13U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x13U)))) {
        vlSymsp->__Vcoverage[6425].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x13U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x13U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x14U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x14U)))) {
        vlSymsp->__Vcoverage[6426].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x14U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x14U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x15U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x15U)))) {
        vlSymsp->__Vcoverage[6427].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x15U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x15U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x16U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x16U)))) {
        vlSymsp->__Vcoverage[6428].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x16U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x16U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x17U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x17U)))) {
        vlSymsp->__Vcoverage[6429].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x17U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x17U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x18U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x18U)))) {
        vlSymsp->__Vcoverage[6430].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x18U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x18U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x19U) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x19U)))) {
        vlSymsp->__Vcoverage[6431].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x19U, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x19U)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1aU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x1aU)))) {
        vlSymsp->__Vcoverage[6432].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x1aU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1aU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1bU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x1bU)))) {
        vlSymsp->__Vcoverage[6433].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x1bU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1bU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1cU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x1cU)))) {
        vlSymsp->__Vcoverage[6434].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x1cU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1cU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1dU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x1dU)))) {
        vlSymsp->__Vcoverage[6435].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x1dU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1dU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1eU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x1eU)))) {
        vlSymsp->__Vcoverage[6436].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x1eU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1eU)));
    }
    if ((1U & (VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1fU) 
               ^ VL_BITSEL_IWII(77, vlSelf->__Vtogcov__msg, 0x1fU)))) {
        vlSymsp->__Vcoverage[6437].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_WI(0x1fU, vlSelf->__Vtogcov__msg, 
                        (1U & VL_BITSEL_IWII(77, vlSelf->__PVT__msg, 0x1fU)));
    }
    vlSelf->__PVT__opaque = (0xffU & VL_SEL_IWII(77, vlSelf->__PVT__msg, 0x42U, 8U));
    vlSelf->__PVT__addr = VL_SEL_IWII(77, vlSelf->__PVT__msg, 0x22U, 0x20U);
    vlSelf->__PVT__data = VL_SEL_IWII(77, vlSelf->__PVT__msg, 0U, 0x20U);
    if ((1U & (VL_BITSEL_IIII(2, (IData)(vlSelf->__PVT__len), 0U) 
               ^ VL_BITSEL_IIII(2, (IData)(vlSelf->__Vtogcov__len), 0U)))) {
        vlSymsp->__Vcoverage[6481].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0U, vlSelf->__Vtogcov__len, 
                        (1U & VL_BITSEL_IIII(2, (IData)(vlSelf->__PVT__len), 0U)));
    }
    if ((1U & (VL_BITSEL_IIII(2, (IData)(vlSelf->__PVT__len), 1U) 
               ^ VL_BITSEL_IIII(2, (IData)(vlSelf->__Vtogcov__len), 1U)))) {
        vlSymsp->__Vcoverage[6482].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(1U, vlSelf->__Vtogcov__len, 
                        (1U & VL_BITSEL_IIII(2, (IData)(vlSelf->__PVT__len), 1U)));
    }
    if ((1U & (VL_BITSEL_IIII(3, (IData)(vlSelf->__PVT__type_), 0U) 
               ^ VL_BITSEL_IIII(3, (IData)(vlSelf->__Vtogcov__type_), 0U)))) {
        vlSymsp->__Vcoverage[6438].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0U, vlSelf->__Vtogcov__type_, 
                        (1U & VL_BITSEL_IIII(3, (IData)(vlSelf->__PVT__type_), 0U)));
    }
    if ((1U & (VL_BITSEL_IIII(3, (IData)(vlSelf->__PVT__type_), 1U) 
               ^ VL_BITSEL_IIII(3, (IData)(vlSelf->__Vtogcov__type_), 1U)))) {
        vlSymsp->__Vcoverage[6439].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(1U, vlSelf->__Vtogcov__type_, 
                        (1U & VL_BITSEL_IIII(3, (IData)(vlSelf->__PVT__type_), 1U)));
    }
    if ((1U & (VL_BITSEL_IIII(3, (IData)(vlSelf->__PVT__type_), 2U) 
               ^ VL_BITSEL_IIII(3, (IData)(vlSelf->__Vtogcov__type_), 2U)))) {
        vlSymsp->__Vcoverage[6440].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(2U, vlSelf->__Vtogcov__type_, 
                        (1U & VL_BITSEL_IIII(3, (IData)(vlSelf->__PVT__type_), 2U)));
    }
    if ((1U & (VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 0U) 
               ^ VL_BITSEL_IIII(8, (IData)(vlSelf->__Vtogcov__opaque), 0U)))) {
        vlSymsp->__Vcoverage[6441].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0U, vlSelf->__Vtogcov__opaque, 
                        (1U & VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 0U)));
    }
    if ((1U & (VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 1U) 
               ^ VL_BITSEL_IIII(8, (IData)(vlSelf->__Vtogcov__opaque), 1U)))) {
        vlSymsp->__Vcoverage[6442].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(1U, vlSelf->__Vtogcov__opaque, 
                        (1U & VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 1U)));
    }
    if ((1U & (VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 2U) 
               ^ VL_BITSEL_IIII(8, (IData)(vlSelf->__Vtogcov__opaque), 2U)))) {
        vlSymsp->__Vcoverage[6443].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(2U, vlSelf->__Vtogcov__opaque, 
                        (1U & VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 2U)));
    }
    if ((1U & (VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 3U) 
               ^ VL_BITSEL_IIII(8, (IData)(vlSelf->__Vtogcov__opaque), 3U)))) {
        vlSymsp->__Vcoverage[6444].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(3U, vlSelf->__Vtogcov__opaque, 
                        (1U & VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 3U)));
    }
    if ((1U & (VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 4U) 
               ^ VL_BITSEL_IIII(8, (IData)(vlSelf->__Vtogcov__opaque), 4U)))) {
        vlSymsp->__Vcoverage[6445].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(4U, vlSelf->__Vtogcov__opaque, 
                        (1U & VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 4U)));
    }
    if ((1U & (VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 5U) 
               ^ VL_BITSEL_IIII(8, (IData)(vlSelf->__Vtogcov__opaque), 5U)))) {
        vlSymsp->__Vcoverage[6446].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(5U, vlSelf->__Vtogcov__opaque, 
                        (1U & VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 5U)));
    }
    if ((1U & (VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 6U) 
               ^ VL_BITSEL_IIII(8, (IData)(vlSelf->__Vtogcov__opaque), 6U)))) {
        vlSymsp->__Vcoverage[6447].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(6U, vlSelf->__Vtogcov__opaque, 
                        (1U & VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 6U)));
    }
    if ((1U & (VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 7U) 
               ^ VL_BITSEL_IIII(8, (IData)(vlSelf->__Vtogcov__opaque), 7U)))) {
        vlSymsp->__Vcoverage[6448].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(7U, vlSelf->__Vtogcov__opaque, 
                        (1U & VL_BITSEL_IIII(8, (IData)(vlSelf->__PVT__opaque), 7U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0U)))) {
        vlSymsp->__Vcoverage[6449].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 1U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 1U)))) {
        vlSymsp->__Vcoverage[6450].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(1U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 1U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 2U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 2U)))) {
        vlSymsp->__Vcoverage[6451].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(2U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 2U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 3U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 3U)))) {
        vlSymsp->__Vcoverage[6452].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(3U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 3U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 4U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 4U)))) {
        vlSymsp->__Vcoverage[6453].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(4U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 4U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 5U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 5U)))) {
        vlSymsp->__Vcoverage[6454].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(5U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 5U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 6U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 6U)))) {
        vlSymsp->__Vcoverage[6455].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(6U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 6U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 7U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 7U)))) {
        vlSymsp->__Vcoverage[6456].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(7U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 7U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 8U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 8U)))) {
        vlSymsp->__Vcoverage[6457].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(8U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 8U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 9U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 9U)))) {
        vlSymsp->__Vcoverage[6458].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(9U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 9U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xaU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0xaU)))) {
        vlSymsp->__Vcoverage[6459].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xaU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xaU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xbU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0xbU)))) {
        vlSymsp->__Vcoverage[6460].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xbU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xbU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xcU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0xcU)))) {
        vlSymsp->__Vcoverage[6461].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xcU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xcU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xdU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0xdU)))) {
        vlSymsp->__Vcoverage[6462].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xdU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xdU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xeU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0xeU)))) {
        vlSymsp->__Vcoverage[6463].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xeU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xeU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xfU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0xfU)))) {
        vlSymsp->__Vcoverage[6464].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xfU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0xfU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x10U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x10U)))) {
        vlSymsp->__Vcoverage[6465].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x10U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x10U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x11U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x11U)))) {
        vlSymsp->__Vcoverage[6466].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x11U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x11U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x12U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x12U)))) {
        vlSymsp->__Vcoverage[6467].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x12U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x12U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x13U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x13U)))) {
        vlSymsp->__Vcoverage[6468].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x13U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x13U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x14U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x14U)))) {
        vlSymsp->__Vcoverage[6469].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x14U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x14U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x15U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x15U)))) {
        vlSymsp->__Vcoverage[6470].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x15U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x15U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x16U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x16U)))) {
        vlSymsp->__Vcoverage[6471].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x16U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x16U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x17U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x17U)))) {
        vlSymsp->__Vcoverage[6472].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x17U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x17U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x18U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x18U)))) {
        vlSymsp->__Vcoverage[6473].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x18U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x18U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x19U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x19U)))) {
        vlSymsp->__Vcoverage[6474].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x19U, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x19U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1aU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x1aU)))) {
        vlSymsp->__Vcoverage[6475].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1aU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1aU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1bU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x1bU)))) {
        vlSymsp->__Vcoverage[6476].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1bU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1bU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1cU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x1cU)))) {
        vlSymsp->__Vcoverage[6477].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1cU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1cU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1dU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x1dU)))) {
        vlSymsp->__Vcoverage[6478].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1dU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1dU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1eU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x1eU)))) {
        vlSymsp->__Vcoverage[6479].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1eU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1eU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1fU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__addr, 0x1fU)))) {
        vlSymsp->__Vcoverage[6480].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1fU, vlSelf->__Vtogcov__addr, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__addr, 0x1fU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0U)))) {
        vlSymsp->__Vcoverage[6483].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 1U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 1U)))) {
        vlSymsp->__Vcoverage[6484].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(1U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 1U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 2U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 2U)))) {
        vlSymsp->__Vcoverage[6485].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(2U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 2U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 3U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 3U)))) {
        vlSymsp->__Vcoverage[6486].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(3U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 3U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 4U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 4U)))) {
        vlSymsp->__Vcoverage[6487].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(4U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 4U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 5U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 5U)))) {
        vlSymsp->__Vcoverage[6488].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(5U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 5U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 6U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 6U)))) {
        vlSymsp->__Vcoverage[6489].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(6U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 6U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 7U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 7U)))) {
        vlSymsp->__Vcoverage[6490].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(7U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 7U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 8U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 8U)))) {
        vlSymsp->__Vcoverage[6491].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(8U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 8U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 9U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 9U)))) {
        vlSymsp->__Vcoverage[6492].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(9U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 9U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xaU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0xaU)))) {
        vlSymsp->__Vcoverage[6493].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xaU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xaU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xbU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0xbU)))) {
        vlSymsp->__Vcoverage[6494].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xbU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xbU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xcU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0xcU)))) {
        vlSymsp->__Vcoverage[6495].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xcU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xcU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xdU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0xdU)))) {
        vlSymsp->__Vcoverage[6496].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xdU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xdU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xeU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0xeU)))) {
        vlSymsp->__Vcoverage[6497].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xeU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xeU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xfU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0xfU)))) {
        vlSymsp->__Vcoverage[6498].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0xfU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0xfU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x10U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x10U)))) {
        vlSymsp->__Vcoverage[6499].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x10U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x10U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x11U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x11U)))) {
        vlSymsp->__Vcoverage[6500].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x11U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x11U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x12U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x12U)))) {
        vlSymsp->__Vcoverage[6501].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x12U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x12U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x13U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x13U)))) {
        vlSymsp->__Vcoverage[6502].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x13U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x13U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x14U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x14U)))) {
        vlSymsp->__Vcoverage[6503].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x14U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x14U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x15U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x15U)))) {
        vlSymsp->__Vcoverage[6504].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x15U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x15U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x16U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x16U)))) {
        vlSymsp->__Vcoverage[6505].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x16U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x16U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x17U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x17U)))) {
        vlSymsp->__Vcoverage[6506].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x17U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x17U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x18U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x18U)))) {
        vlSymsp->__Vcoverage[6507].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x18U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x18U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x19U) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x19U)))) {
        vlSymsp->__Vcoverage[6508].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x19U, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x19U)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1aU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x1aU)))) {
        vlSymsp->__Vcoverage[6509].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1aU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1aU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1bU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x1bU)))) {
        vlSymsp->__Vcoverage[6510].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1bU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1bU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1cU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x1cU)))) {
        vlSymsp->__Vcoverage[6511].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1cU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1cU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1dU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x1dU)))) {
        vlSymsp->__Vcoverage[6512].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1dU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1dU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1eU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x1eU)))) {
        vlSymsp->__Vcoverage[6513].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1eU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1eU)));
    }
    if ((1U & (VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1fU) 
               ^ VL_BITSEL_IIII(32, vlSelf->__Vtogcov__data, 0x1fU)))) {
        vlSymsp->__Vcoverage[6514].fetch_add(1, std::memory_order_relaxed);
        VL_ASSIGNBIT_II(0x1fU, vlSelf->__Vtogcov__data, 
                        (1U & VL_BITSEL_IIII(32, vlSelf->__PVT__data, 0x1fU)));
    }
}

VL_INLINE_OPT void Vtop_vc_MemReqMsg4BTrace___nba_comb__TOP__top__mem__memreq1_trace__2(Vtop_vc_MemReqMsg4BTrace* vlSelf) {
    if (false && vlSelf) {}  // Prevent unused
    Vtop__Syms* const __restrict vlSymsp VL_ATTR_UNUSED = vlSelf->vlSymsp;
    VL_DEBUG_IF(VL_DBG_MSGF("+            Vtop_vc_MemReqMsg4BTrace___nba_comb__TOP__top__mem__memreq1_trace__2\n"); );
    // Body
    if (((IData)(vlSelf->__PVT__rdy) ^ (IData)(vlSelf->__Vtogcov__rdy))) {
        vlSymsp->__Vcoverage[6360].fetch_add(1, std::memory_order_relaxed);
        vlSelf->__Vtogcov__rdy = vlSelf->__PVT__rdy;
    }
}
